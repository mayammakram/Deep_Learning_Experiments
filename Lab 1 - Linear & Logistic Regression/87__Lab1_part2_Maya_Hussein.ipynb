{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bxGkToGpFrJ"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/sherifmost/DeepLearning/blob/master/Labs/lab1/lab1_part2.ipynb\">\n",
        "        <img src=\"http://introtodeeplearning.com/images/colab/colab.png?v2.0\"  style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6OFYzfbpHX6"
      },
      "source": [
        "# Copyright Information\n",
        "\n",
        "**Parts of this lab are based on Kaggle kernels.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA5NHvtepVUX"
      },
      "source": [
        "# Lab 1 - Part2: Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JgGI_Q82Dor"
      },
      "source": [
        "![Logistic Regression](https://raw.githubusercontent.com/KhaledElTahan/AUC-DeepLearning/master/Labs/lab1/logistic_regression.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbWcnTT02NPV"
      },
      "source": [
        "## 1.2.1 Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhU6-7Mx2TVB"
      },
      "source": [
        "Here, we are trying to increase the people's attention regarding the heart diseases. Like any disease, it is always better to know if you are sick early so you can get the treatment you need before it is too late. Therefore, we use a dataset that gathered some information about two groups: a group with a heart disease and the other group has no disease.\n",
        "The gathered information includes age, chest pain type, fasting blood sugar, etc. \n",
        "\n",
        "Your goal is to train a logistic regression model to predict if a person has a heart disease or not depending on the given information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PTcUN4K24pK"
      },
      "source": [
        "## 1.2.2 Problem Details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofHL4e073Ca0"
      },
      "source": [
        "Let's dive into the code, explain it and show you the parts you need to fill!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjQNwFqC4NEM"
      },
      "source": [
        "### 1.2.2.1 Import Needed packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0AnpII84Pdw"
      },
      "source": [
        "Pay close attention to the packages I imported for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "id": "L0_d4RG4zcC_",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, RMSprop\n",
        "from tensorflow.keras.initializers import RandomNormal, RandomUniform\n",
        "from tensorflow.keras.losses import BinaryCrossentropy, CategoricalHinge\n",
        "from tensorflow.keras import regularizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePGBlsWk4ner"
      },
      "source": [
        "### 1.2.2.2 Work on the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR6WYKSo5tRH"
      },
      "source": [
        "This dataset contains 13 features that demonstrate the health state of a person and our target (0 if this person does not have a heart disease and 1 if he has a heart disease.)\n",
        "\n",
        "We first load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "PRxqN_IPo6Fg",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"https://raw.githubusercontent.com/KhaledElTahan/DeepLearning/master/Labs/lab1/lab1_heart.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGsChzk_55nr"
      },
      "source": [
        "A sneak peak on the dataset and how it looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jRQkXsiHrTBB",
        "outputId": "c3dbc94a-ed30-4d57-d862-278ef2324536",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1c7aa0c8-37d0-4b17-b3c9-51a0647cda94\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c7aa0c8-37d0-4b17-b3c9-51a0647cda94')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1c7aa0c8-37d0-4b17-b3c9-51a0647cda94 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1c7aa0c8-37d0-4b17-b3c9-51a0647cda94');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ]
          },
          "execution_count": 212,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJa4KJEV6AFm"
      },
      "source": [
        "Define input and output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "I1UDjkHZrbey",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "X = dataset.iloc[:, 0:13].values\n",
        "y = dataset.iloc[:, 13].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTd_AkXK6Y1G"
      },
      "source": [
        "**TODO: Preprocess your data**\n",
        "\n",
        "1.   Do you need to scale the data? Which type of scaling is better? \n",
        "2.   Perhaps you might want to add non-linearity by adding artificial features.\n",
        "\n",
        "![The effect of the boundary with artificial features](https://raw.githubusercontent.com/KhaledElTahan/AUC-DeepLearning/master/Labs/lab1/artificial_features_boundaries.png)\n",
        "\n",
        "You might have a look on part1 preprocessing and take hints from there. \n",
        "\n",
        "**Try different types of data preprocessing and include their effect on the accuracy in your report.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "RyDjY4ECpenA",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Concatenate all the data\n",
        "# We do this to be able to preprocess on the whole dataset\n",
        "all_data = dataset.iloc\n",
        "#all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
        "#                      test.loc[:,'MSSubClass':'SaleCondition']))\n",
        "\n",
        "# Log transform the target y in training data - by reference inside all\n",
        "dataset[\"target\"] = np.log1p(dataset[\"target\"])\n",
        "\n",
        "# Log transform skewed numeric features:\n",
        "\n",
        "# Get Numerical Fields\n",
        "# numeric_feats = all_data\n",
        "\n",
        "# skewed_feats = X[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewnessc\n",
        "# skewed_feats = skewed_feats[skewed_feats > 0.75] # Get Skewed Columns\n",
        "# skewed_feats = skewed_feats.index # Get Skewed Columns indices\n",
        "\n",
        "# # Log scale skewed columns\n",
        "# # Normalize the skewed distribution for better regression\n",
        "# all_data[skewed_feats] = np.log1p(all_data[skewed_feats])\n",
        "\n",
        "# Create Dummy variables for the categorical features \n",
        "all_data = pd.get_dummies(all_data) \n",
        "\n",
        "cubic_X = X ** 2\n",
        "X = np.concatenate((X, cubic_X), axis=1)\n",
        "# Replace the numeric missing values (NaN's) with the mean of their respective columns\n",
        "#all_data = all_data.fillna(all_data.mean())\n",
        "\n",
        "# # Split the data to training & testing\n",
        "# X_train = X[:X.shape[0]]\n",
        "# X_test = X[X.shape[0]:]\n",
        "\n",
        "\n",
        "# Standardize features by removing the mean and scaling to unit variance\n",
        "# z = (x - u) / s\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "# #split training data into training & validation, default splitting is 25% validation\n",
        "# X_tr, X_val, y_tr, y_val = train_test_split(X_train, y, random_state = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv6Cy9ar6ewP"
      },
      "source": [
        "Split dataset into, training, validation and testing splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "id": "NCBELT8wpsrq",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Get Training Data\n",
        "train_X, temporary_X, train_y, temporary_y = train_test_split(X, y, train_size=0.75, random_state=0)\n",
        "\n",
        "# Get Validation & Testing Data\n",
        "val_X, test_X, val_y, test_y = train_test_split(temporary_X, temporary_y, train_size=0.5, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tk5uv_H26p5M"
      },
      "source": [
        "### 1.2.2.3 Define your model here (TODO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eWXVX966kiM"
      },
      "source": [
        "Logistic Regression as a model is exactly like the Linear Regression except for the activation function. \n",
        "\n",
        "Use this fact to define your model similar to part1 except for the actication function.\n",
        "\n",
        "![Logistic Regression using Simple Perceptron](https://raw.githubusercontent.com/KhaledElTahan/AUC-DeepLearning/master/Labs/lab1/perceptron_activation.png)\n",
        "\n",
        "**TODO**: \n",
        "1. Try different activation functions and include in the report their effect on the accuracy and the training plot.\n",
        "2. Try different regularizers and include in the report their effect on the accuracy and the training plot.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "tqJwVMxdptTz",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "activation = 'sigmoid'\n",
        "regularizer = regularizers.l2(0.01)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFHo5TzW_yCw"
      },
      "source": [
        "### 1.2.2.4 Compile your model and print a summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoaNNu-z6m2j"
      },
      "source": [
        "**TODO**\n",
        "1. Try different losses functions and include in the report their effect on the accuracy. Make sure that those losses functions are meant only for classification! Don't use losses functions that are meant for prediction!\n",
        "2. Try different optimizers and include in the report their effect on the accuracy and the training plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {
        "id": "i5WXiT2kpv66",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## TODO Try Different losses & optimizers here\n",
        "model.compile(loss=BinaryCrossentropy(), metrics=['accuracy'], optimizer=Adam())\n",
        "#model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcTmEu8AAA4W"
      },
      "source": [
        "### 1.2.2.5 Train your model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBhupRN6_39e",
        "outputId": "07c93ae4-f7f8-4d4c-f8bd-6b0ac116b3c3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "15/15 [==============================] - 1s 15ms/step - loss: 5.6108 - accuracy: 0.4714 - val_loss: 6.2803 - val_accuracy: 0.4737\n",
            "Epoch 2/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.4015 - accuracy: 0.4758 - val_loss: 6.2634 - val_accuracy: 0.4737\n",
            "Epoch 3/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.3762 - accuracy: 0.4802 - val_loss: 6.2569 - val_accuracy: 0.4737\n",
            "Epoch 4/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.3658 - accuracy: 0.4846 - val_loss: 6.2502 - val_accuracy: 0.4737\n",
            "Epoch 5/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.3547 - accuracy: 0.4890 - val_loss: 5.9634 - val_accuracy: 0.4737\n",
            "Epoch 6/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.3143 - accuracy: 0.4890 - val_loss: 5.9233 - val_accuracy: 0.4737\n",
            "Epoch 7/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2975 - accuracy: 0.4846 - val_loss: 5.9168 - val_accuracy: 0.4737\n",
            "Epoch 8/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2797 - accuracy: 0.4846 - val_loss: 5.9085 - val_accuracy: 0.4737\n",
            "Epoch 9/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2717 - accuracy: 0.4934 - val_loss: 5.8998 - val_accuracy: 0.4737\n",
            "Epoch 10/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2651 - accuracy: 0.4934 - val_loss: 5.8914 - val_accuracy: 0.4737\n",
            "Epoch 11/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.2607 - accuracy: 0.5022 - val_loss: 5.8842 - val_accuracy: 0.4737\n",
            "Epoch 12/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2542 - accuracy: 0.5066 - val_loss: 5.8801 - val_accuracy: 0.4737\n",
            "Epoch 13/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2508 - accuracy: 0.5066 - val_loss: 5.8744 - val_accuracy: 0.4737\n",
            "Epoch 14/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.2467 - accuracy: 0.5110 - val_loss: 5.8682 - val_accuracy: 0.5000\n",
            "Epoch 15/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2415 - accuracy: 0.5110 - val_loss: 5.8648 - val_accuracy: 0.5000\n",
            "Epoch 16/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2384 - accuracy: 0.5110 - val_loss: 5.8610 - val_accuracy: 0.5000\n",
            "Epoch 17/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2336 - accuracy: 0.5066 - val_loss: 5.8562 - val_accuracy: 0.5000\n",
            "Epoch 18/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2318 - accuracy: 0.5066 - val_loss: 5.5710 - val_accuracy: 0.5000\n",
            "Epoch 19/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.2291 - accuracy: 0.5066 - val_loss: 5.5465 - val_accuracy: 0.5000\n",
            "Epoch 20/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2234 - accuracy: 0.5066 - val_loss: 5.5383 - val_accuracy: 0.5000\n",
            "Epoch 21/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2203 - accuracy: 0.5066 - val_loss: 5.5306 - val_accuracy: 0.5000\n",
            "Epoch 22/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2166 - accuracy: 0.5154 - val_loss: 5.5210 - val_accuracy: 0.5000\n",
            "Epoch 23/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2143 - accuracy: 0.5198 - val_loss: 5.5150 - val_accuracy: 0.5000\n",
            "Epoch 24/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2201 - accuracy: 0.5110 - val_loss: 5.5283 - val_accuracy: 0.5000\n",
            "Epoch 25/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2730 - accuracy: 0.5022 - val_loss: 5.5177 - val_accuracy: 0.5000\n",
            "Epoch 26/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2679 - accuracy: 0.5022 - val_loss: 5.5022 - val_accuracy: 0.5000\n",
            "Epoch 27/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.2102 - accuracy: 0.5066 - val_loss: 5.4873 - val_accuracy: 0.5000\n",
            "Epoch 28/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.1540 - accuracy: 0.5154 - val_loss: 5.4651 - val_accuracy: 0.5000\n",
            "Epoch 29/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.0219 - accuracy: 0.5110 - val_loss: 5.4480 - val_accuracy: 0.5263\n",
            "Epoch 30/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9657 - accuracy: 0.5286 - val_loss: 5.1977 - val_accuracy: 0.5263\n",
            "Epoch 31/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.7886 - accuracy: 0.5286 - val_loss: 5.1368 - val_accuracy: 0.5263\n",
            "Epoch 32/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.7121 - accuracy: 0.5419 - val_loss: 5.1034 - val_accuracy: 0.5263\n",
            "Epoch 33/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.6889 - accuracy: 0.5595 - val_loss: 5.0846 - val_accuracy: 0.5263\n",
            "Epoch 34/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.4440 - accuracy: 0.5727 - val_loss: 4.7117 - val_accuracy: 0.5789\n",
            "Epoch 35/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.3283 - accuracy: 0.5639 - val_loss: 4.1334 - val_accuracy: 0.6053\n",
            "Epoch 36/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 4.2918 - accuracy: 0.5727 - val_loss: 4.0693 - val_accuracy: 0.6316\n",
            "Epoch 37/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.2806 - accuracy: 0.5771 - val_loss: 4.0572 - val_accuracy: 0.6316\n",
            "Epoch 38/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 4.2275 - accuracy: 0.5771 - val_loss: 4.0498 - val_accuracy: 0.6316\n",
            "Epoch 39/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.2165 - accuracy: 0.5727 - val_loss: 4.0448 - val_accuracy: 0.6316\n",
            "Epoch 40/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.2111 - accuracy: 0.5683 - val_loss: 4.0411 - val_accuracy: 0.6316\n",
            "Epoch 41/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.2073 - accuracy: 0.5683 - val_loss: 4.0376 - val_accuracy: 0.6316\n",
            "Epoch 42/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.2037 - accuracy: 0.5727 - val_loss: 4.0345 - val_accuracy: 0.6316\n",
            "Epoch 43/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.2006 - accuracy: 0.5771 - val_loss: 4.0306 - val_accuracy: 0.6316\n",
            "Epoch 44/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.1976 - accuracy: 0.5771 - val_loss: 4.0278 - val_accuracy: 0.6316\n",
            "Epoch 45/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.1943 - accuracy: 0.5815 - val_loss: 4.0264 - val_accuracy: 0.6316\n",
            "Epoch 46/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.1919 - accuracy: 0.5859 - val_loss: 4.0239 - val_accuracy: 0.6316\n",
            "Epoch 47/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.1475 - accuracy: 0.5947 - val_loss: 4.0272 - val_accuracy: 0.6316\n",
            "Epoch 48/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.1334 - accuracy: 0.5903 - val_loss: 4.0474 - val_accuracy: 0.6316\n",
            "Epoch 49/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 4.1247 - accuracy: 0.5859 - val_loss: 4.0538 - val_accuracy: 0.6316\n",
            "Epoch 50/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 4.1216 - accuracy: 0.5859 - val_loss: 4.0512 - val_accuracy: 0.6316\n",
            "Epoch 51/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.1189 - accuracy: 0.5903 - val_loss: 4.0502 - val_accuracy: 0.6316\n",
            "Epoch 52/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.1165 - accuracy: 0.5903 - val_loss: 4.0499 - val_accuracy: 0.6316\n",
            "Epoch 53/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.1139 - accuracy: 0.5903 - val_loss: 4.0524 - val_accuracy: 0.6316\n",
            "Epoch 54/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.1116 - accuracy: 0.5947 - val_loss: 4.0516 - val_accuracy: 0.6316\n",
            "Epoch 55/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.1095 - accuracy: 0.5947 - val_loss: 4.0490 - val_accuracy: 0.6316\n",
            "Epoch 56/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.1070 - accuracy: 0.5947 - val_loss: 4.0531 - val_accuracy: 0.6316\n",
            "Epoch 57/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.0607 - accuracy: 0.5991 - val_loss: 3.7875 - val_accuracy: 0.6316\n",
            "Epoch 58/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.0456 - accuracy: 0.5991 - val_loss: 3.7358 - val_accuracy: 0.6316\n",
            "Epoch 59/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.9963 - accuracy: 0.5991 - val_loss: 3.7128 - val_accuracy: 0.6316\n",
            "Epoch 60/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.9383 - accuracy: 0.5991 - val_loss: 3.6916 - val_accuracy: 0.6316\n",
            "Epoch 61/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.8903 - accuracy: 0.5991 - val_loss: 3.6560 - val_accuracy: 0.6316\n",
            "Epoch 62/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.9169 - accuracy: 0.6123 - val_loss: 3.6067 - val_accuracy: 0.6316\n",
            "Epoch 63/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.8538 - accuracy: 0.6211 - val_loss: 3.5921 - val_accuracy: 0.6316\n",
            "Epoch 64/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7866 - accuracy: 0.6344 - val_loss: 3.5839 - val_accuracy: 0.6316\n",
            "Epoch 65/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7768 - accuracy: 0.6388 - val_loss: 3.5753 - val_accuracy: 0.6316\n",
            "Epoch 66/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7692 - accuracy: 0.6388 - val_loss: 3.5697 - val_accuracy: 0.6316\n",
            "Epoch 67/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7649 - accuracy: 0.6388 - val_loss: 3.5667 - val_accuracy: 0.6316\n",
            "Epoch 68/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7611 - accuracy: 0.6388 - val_loss: 3.5635 - val_accuracy: 0.6316\n",
            "Epoch 69/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7580 - accuracy: 0.6388 - val_loss: 3.5599 - val_accuracy: 0.6316\n",
            "Epoch 70/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7550 - accuracy: 0.6432 - val_loss: 3.5572 - val_accuracy: 0.6316\n",
            "Epoch 71/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7523 - accuracy: 0.6432 - val_loss: 3.5548 - val_accuracy: 0.6316\n",
            "Epoch 72/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.7498 - accuracy: 0.6476 - val_loss: 3.5527 - val_accuracy: 0.6316\n",
            "Epoch 73/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7475 - accuracy: 0.6520 - val_loss: 3.5497 - val_accuracy: 0.6316\n",
            "Epoch 74/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.7448 - accuracy: 0.6564 - val_loss: 3.5479 - val_accuracy: 0.6316\n",
            "Epoch 75/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7422 - accuracy: 0.6564 - val_loss: 3.5458 - val_accuracy: 0.6316\n",
            "Epoch 76/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7400 - accuracy: 0.6564 - val_loss: 3.5438 - val_accuracy: 0.6316\n",
            "Epoch 77/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7380 - accuracy: 0.6564 - val_loss: 3.5418 - val_accuracy: 0.6316\n",
            "Epoch 78/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.7361 - accuracy: 0.6564 - val_loss: 3.5399 - val_accuracy: 0.6316\n",
            "Epoch 79/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7340 - accuracy: 0.6564 - val_loss: 3.5381 - val_accuracy: 0.6316\n",
            "Epoch 80/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.7321 - accuracy: 0.6564 - val_loss: 3.5364 - val_accuracy: 0.6316\n",
            "Epoch 81/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7303 - accuracy: 0.6608 - val_loss: 3.5344 - val_accuracy: 0.6316\n",
            "Epoch 82/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7281 - accuracy: 0.6608 - val_loss: 3.5324 - val_accuracy: 0.6316\n",
            "Epoch 83/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7261 - accuracy: 0.6608 - val_loss: 3.5297 - val_accuracy: 0.6316\n",
            "Epoch 84/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.7240 - accuracy: 0.6608 - val_loss: 3.5276 - val_accuracy: 0.6316\n",
            "Epoch 85/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7220 - accuracy: 0.6608 - val_loss: 3.5256 - val_accuracy: 0.6316\n",
            "Epoch 86/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7202 - accuracy: 0.6652 - val_loss: 3.5240 - val_accuracy: 0.6316\n",
            "Epoch 87/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.7186 - accuracy: 0.6652 - val_loss: 3.5221 - val_accuracy: 0.6316\n",
            "Epoch 88/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.7171 - accuracy: 0.6652 - val_loss: 3.5206 - val_accuracy: 0.6316\n",
            "Epoch 89/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 3.7155 - accuracy: 0.6608 - val_loss: 3.5192 - val_accuracy: 0.6316\n",
            "Epoch 90/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7140 - accuracy: 0.6652 - val_loss: 3.5181 - val_accuracy: 0.6316\n",
            "Epoch 91/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7126 - accuracy: 0.6652 - val_loss: 3.2924 - val_accuracy: 0.6316\n",
            "Epoch 92/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7112 - accuracy: 0.6652 - val_loss: 3.2568 - val_accuracy: 0.6316\n",
            "Epoch 93/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 3.7097 - accuracy: 0.6652 - val_loss: 3.2436 - val_accuracy: 0.6316\n",
            "Epoch 94/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7083 - accuracy: 0.6652 - val_loss: 3.2355 - val_accuracy: 0.6316\n",
            "Epoch 95/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7067 - accuracy: 0.6652 - val_loss: 3.2263 - val_accuracy: 0.6316\n",
            "Epoch 96/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.7053 - accuracy: 0.6652 - val_loss: 3.2178 - val_accuracy: 0.6316\n",
            "Epoch 97/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.6109 - accuracy: 0.6652 - val_loss: 3.1870 - val_accuracy: 0.6316\n",
            "Epoch 98/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4855 - accuracy: 0.6652 - val_loss: 3.1663 - val_accuracy: 0.6316\n",
            "Epoch 99/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.4712 - accuracy: 0.6652 - val_loss: 3.1563 - val_accuracy: 0.6316\n",
            "Epoch 100/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.4643 - accuracy: 0.6652 - val_loss: 3.1499 - val_accuracy: 0.6579\n",
            "Epoch 101/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.4598 - accuracy: 0.6696 - val_loss: 3.1471 - val_accuracy: 0.6579\n",
            "Epoch 102/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.4568 - accuracy: 0.6696 - val_loss: 3.1431 - val_accuracy: 0.6579\n",
            "Epoch 103/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4533 - accuracy: 0.6696 - val_loss: 3.1405 - val_accuracy: 0.6579\n",
            "Epoch 104/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4506 - accuracy: 0.6652 - val_loss: 3.1379 - val_accuracy: 0.6579\n",
            "Epoch 105/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4482 - accuracy: 0.6652 - val_loss: 3.1350 - val_accuracy: 0.6579\n",
            "Epoch 106/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4456 - accuracy: 0.6784 - val_loss: 3.1325 - val_accuracy: 0.6579\n",
            "Epoch 107/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4434 - accuracy: 0.6784 - val_loss: 3.1299 - val_accuracy: 0.6579\n",
            "Epoch 108/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.4413 - accuracy: 0.6784 - val_loss: 3.1281 - val_accuracy: 0.6579\n",
            "Epoch 109/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 3.4394 - accuracy: 0.6828 - val_loss: 3.1257 - val_accuracy: 0.6579\n",
            "Epoch 110/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4374 - accuracy: 0.6828 - val_loss: 2.9144 - val_accuracy: 0.6579\n",
            "Epoch 111/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.4357 - accuracy: 0.6828 - val_loss: 2.8474 - val_accuracy: 0.6579\n",
            "Epoch 112/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4339 - accuracy: 0.6872 - val_loss: 2.8261 - val_accuracy: 0.6842\n",
            "Epoch 113/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4321 - accuracy: 0.6872 - val_loss: 2.8156 - val_accuracy: 0.6842\n",
            "Epoch 114/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4307 - accuracy: 0.6872 - val_loss: 2.8067 - val_accuracy: 0.6842\n",
            "Epoch 115/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.3481 - accuracy: 0.6916 - val_loss: 2.7569 - val_accuracy: 0.6842\n",
            "Epoch 116/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.0079 - accuracy: 0.7048 - val_loss: 2.4561 - val_accuracy: 0.6842\n",
            "Epoch 117/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9382 - accuracy: 0.7137 - val_loss: 2.4298 - val_accuracy: 0.7105\n",
            "Epoch 118/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9342 - accuracy: 0.7137 - val_loss: 2.4167 - val_accuracy: 0.7105\n",
            "Epoch 119/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9323 - accuracy: 0.7137 - val_loss: 2.4088 - val_accuracy: 0.7105\n",
            "Epoch 120/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9312 - accuracy: 0.7137 - val_loss: 2.3998 - val_accuracy: 0.7105\n",
            "Epoch 121/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9301 - accuracy: 0.7137 - val_loss: 2.3933 - val_accuracy: 0.7105\n",
            "Epoch 122/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9291 - accuracy: 0.7137 - val_loss: 2.3900 - val_accuracy: 0.7105\n",
            "Epoch 123/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.9282 - accuracy: 0.7181 - val_loss: 2.3842 - val_accuracy: 0.7105\n",
            "Epoch 124/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9274 - accuracy: 0.7181 - val_loss: 2.3801 - val_accuracy: 0.7105\n",
            "Epoch 125/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9265 - accuracy: 0.7181 - val_loss: 2.3754 - val_accuracy: 0.7105\n",
            "Epoch 126/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9258 - accuracy: 0.7181 - val_loss: 2.3725 - val_accuracy: 0.7105\n",
            "Epoch 127/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9251 - accuracy: 0.7181 - val_loss: 2.3690 - val_accuracy: 0.7105\n",
            "Epoch 128/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9245 - accuracy: 0.7181 - val_loss: 2.3655 - val_accuracy: 0.7105\n",
            "Epoch 129/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9240 - accuracy: 0.7181 - val_loss: 2.3614 - val_accuracy: 0.7105\n",
            "Epoch 130/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9232 - accuracy: 0.7181 - val_loss: 2.3587 - val_accuracy: 0.7105\n",
            "Epoch 131/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9226 - accuracy: 0.7181 - val_loss: 2.3566 - val_accuracy: 0.7105\n",
            "Epoch 132/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9222 - accuracy: 0.7181 - val_loss: 2.3539 - val_accuracy: 0.7105\n",
            "Epoch 133/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9218 - accuracy: 0.7181 - val_loss: 2.3514 - val_accuracy: 0.7105\n",
            "Epoch 134/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9213 - accuracy: 0.7181 - val_loss: 2.3492 - val_accuracy: 0.7105\n",
            "Epoch 135/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9208 - accuracy: 0.7181 - val_loss: 2.3458 - val_accuracy: 0.7105\n",
            "Epoch 136/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9203 - accuracy: 0.7181 - val_loss: 2.3441 - val_accuracy: 0.7105\n",
            "Epoch 137/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9198 - accuracy: 0.7181 - val_loss: 2.3421 - val_accuracy: 0.7105\n",
            "Epoch 138/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9194 - accuracy: 0.7181 - val_loss: 2.3402 - val_accuracy: 0.7105\n",
            "Epoch 139/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9192 - accuracy: 0.7181 - val_loss: 2.3378 - val_accuracy: 0.7105\n",
            "Epoch 140/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9187 - accuracy: 0.7181 - val_loss: 2.3360 - val_accuracy: 0.7105\n",
            "Epoch 141/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9185 - accuracy: 0.7181 - val_loss: 2.3349 - val_accuracy: 0.7105\n",
            "Epoch 142/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9181 - accuracy: 0.7181 - val_loss: 2.3388 - val_accuracy: 0.7105\n",
            "Epoch 143/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9183 - accuracy: 0.7181 - val_loss: 2.3385 - val_accuracy: 0.7105\n",
            "Epoch 144/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.9179 - accuracy: 0.7181 - val_loss: 2.3364 - val_accuracy: 0.7105\n",
            "Epoch 145/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9175 - accuracy: 0.7181 - val_loss: 2.3338 - val_accuracy: 0.7105\n",
            "Epoch 146/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9169 - accuracy: 0.7181 - val_loss: 2.3325 - val_accuracy: 0.7105\n",
            "Epoch 147/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9165 - accuracy: 0.7181 - val_loss: 2.3304 - val_accuracy: 0.7105\n",
            "Epoch 148/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9163 - accuracy: 0.7181 - val_loss: 2.3289 - val_accuracy: 0.7105\n",
            "Epoch 149/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.9159 - accuracy: 0.7181 - val_loss: 2.3318 - val_accuracy: 0.7105\n",
            "Epoch 150/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9161 - accuracy: 0.7181 - val_loss: 2.3308 - val_accuracy: 0.7105\n",
            "Epoch 151/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9158 - accuracy: 0.7181 - val_loss: 2.3289 - val_accuracy: 0.7105\n",
            "Epoch 152/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9153 - accuracy: 0.7181 - val_loss: 2.3272 - val_accuracy: 0.7105\n",
            "Epoch 153/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9151 - accuracy: 0.7181 - val_loss: 2.3247 - val_accuracy: 0.7105\n",
            "Epoch 154/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9146 - accuracy: 0.7181 - val_loss: 2.3239 - val_accuracy: 0.7105\n",
            "Epoch 155/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9141 - accuracy: 0.7181 - val_loss: 2.3221 - val_accuracy: 0.7105\n",
            "Epoch 156/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9137 - accuracy: 0.7181 - val_loss: 2.3209 - val_accuracy: 0.7105\n",
            "Epoch 157/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9134 - accuracy: 0.7181 - val_loss: 2.3192 - val_accuracy: 0.7105\n",
            "Epoch 158/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9131 - accuracy: 0.7137 - val_loss: 2.3183 - val_accuracy: 0.7105\n",
            "Epoch 159/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9128 - accuracy: 0.7137 - val_loss: 2.3178 - val_accuracy: 0.7105\n",
            "Epoch 160/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9125 - accuracy: 0.7137 - val_loss: 2.3155 - val_accuracy: 0.7105\n",
            "Epoch 161/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9120 - accuracy: 0.7137 - val_loss: 2.3123 - val_accuracy: 0.7105\n",
            "Epoch 162/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9118 - accuracy: 0.7137 - val_loss: 2.3112 - val_accuracy: 0.7105\n",
            "Epoch 163/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.9115 - accuracy: 0.7137 - val_loss: 2.3102 - val_accuracy: 0.7105\n",
            "Epoch 164/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.9113 - accuracy: 0.7137 - val_loss: 2.3091 - val_accuracy: 0.7105\n",
            "Epoch 165/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9111 - accuracy: 0.7137 - val_loss: 2.3090 - val_accuracy: 0.7105\n",
            "Epoch 166/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9107 - accuracy: 0.7137 - val_loss: 2.3084 - val_accuracy: 0.7105\n",
            "Epoch 167/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9106 - accuracy: 0.7137 - val_loss: 2.3071 - val_accuracy: 0.7105\n",
            "Epoch 168/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.9101 - accuracy: 0.7093 - val_loss: 2.3063 - val_accuracy: 0.7105\n",
            "Epoch 169/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9099 - accuracy: 0.7093 - val_loss: 2.3047 - val_accuracy: 0.7105\n",
            "Epoch 170/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.9097 - accuracy: 0.7093 - val_loss: 2.3041 - val_accuracy: 0.7105\n",
            "Epoch 171/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9093 - accuracy: 0.7093 - val_loss: 2.3034 - val_accuracy: 0.7105\n",
            "Epoch 172/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.9088 - accuracy: 0.7093 - val_loss: 2.3030 - val_accuracy: 0.7105\n",
            "Epoch 173/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.8800 - accuracy: 0.7137 - val_loss: 2.2711 - val_accuracy: 0.7105\n",
            "Epoch 174/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.7256 - accuracy: 0.7225 - val_loss: 2.2363 - val_accuracy: 0.7632\n",
            "Epoch 175/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.7179 - accuracy: 0.7313 - val_loss: 2.2317 - val_accuracy: 0.7632\n",
            "Epoch 176/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.7161 - accuracy: 0.7313 - val_loss: 2.2301 - val_accuracy: 0.7632\n",
            "Epoch 177/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.7143 - accuracy: 0.7313 - val_loss: 2.2293 - val_accuracy: 0.7632\n",
            "Epoch 178/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.7129 - accuracy: 0.7313 - val_loss: 2.2286 - val_accuracy: 0.7632\n",
            "Epoch 179/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.7116 - accuracy: 0.7313 - val_loss: 2.2276 - val_accuracy: 0.7632\n",
            "Epoch 180/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.7104 - accuracy: 0.7313 - val_loss: 2.2270 - val_accuracy: 0.7632\n",
            "Epoch 181/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.7091 - accuracy: 0.7313 - val_loss: 2.2260 - val_accuracy: 0.7632\n",
            "Epoch 182/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.7080 - accuracy: 0.7313 - val_loss: 2.2252 - val_accuracy: 0.7632\n",
            "Epoch 183/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.7069 - accuracy: 0.7313 - val_loss: 2.2242 - val_accuracy: 0.7632\n",
            "Epoch 184/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.7057 - accuracy: 0.7313 - val_loss: 2.2236 - val_accuracy: 0.7895\n",
            "Epoch 185/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.7046 - accuracy: 0.7313 - val_loss: 2.2229 - val_accuracy: 0.7895\n",
            "Epoch 186/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.7034 - accuracy: 0.7313 - val_loss: 2.2225 - val_accuracy: 0.7895\n",
            "Epoch 187/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.7024 - accuracy: 0.7357 - val_loss: 2.2220 - val_accuracy: 0.7895\n",
            "Epoch 188/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.7016 - accuracy: 0.7357 - val_loss: 2.2214 - val_accuracy: 0.7895\n",
            "Epoch 189/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.7006 - accuracy: 0.7357 - val_loss: 2.2206 - val_accuracy: 0.7895\n",
            "Epoch 190/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.6603 - accuracy: 0.7357 - val_loss: 2.2185 - val_accuracy: 0.7895\n",
            "Epoch 191/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.5636 - accuracy: 0.7401 - val_loss: 2.2178 - val_accuracy: 0.7895\n",
            "Epoch 192/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.5555 - accuracy: 0.7489 - val_loss: 2.2171 - val_accuracy: 0.7895\n",
            "Epoch 193/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.5036 - accuracy: 0.7489 - val_loss: 2.2158 - val_accuracy: 0.7895\n",
            "Epoch 194/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.4515 - accuracy: 0.7445 - val_loss: 2.2124 - val_accuracy: 0.7895\n",
            "Epoch 195/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.4377 - accuracy: 0.7445 - val_loss: 2.2109 - val_accuracy: 0.8158\n",
            "Epoch 196/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.4345 - accuracy: 0.7445 - val_loss: 2.2099 - val_accuracy: 0.8158\n",
            "Epoch 197/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.4329 - accuracy: 0.7445 - val_loss: 2.2090 - val_accuracy: 0.8158\n",
            "Epoch 198/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.4315 - accuracy: 0.7401 - val_loss: 2.2080 - val_accuracy: 0.8158\n",
            "Epoch 199/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.4300 - accuracy: 0.7401 - val_loss: 2.2071 - val_accuracy: 0.8158\n",
            "Epoch 200/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.4287 - accuracy: 0.7401 - val_loss: 2.2064 - val_accuracy: 0.8158\n",
            "Epoch 201/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.4276 - accuracy: 0.7445 - val_loss: 2.2055 - val_accuracy: 0.8158\n",
            "Epoch 202/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3826 - accuracy: 0.7445 - val_loss: 2.2036 - val_accuracy: 0.8158\n",
            "Epoch 203/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3685 - accuracy: 0.7445 - val_loss: 2.1986 - val_accuracy: 0.8158\n",
            "Epoch 204/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3651 - accuracy: 0.7445 - val_loss: 2.1966 - val_accuracy: 0.8158\n",
            "Epoch 205/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3624 - accuracy: 0.7445 - val_loss: 2.1955 - val_accuracy: 0.8158\n",
            "Epoch 206/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3609 - accuracy: 0.7445 - val_loss: 2.1947 - val_accuracy: 0.8158\n",
            "Epoch 207/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3596 - accuracy: 0.7445 - val_loss: 2.1939 - val_accuracy: 0.8158\n",
            "Epoch 208/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3584 - accuracy: 0.7445 - val_loss: 2.1932 - val_accuracy: 0.8158\n",
            "Epoch 209/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3574 - accuracy: 0.7445 - val_loss: 2.1924 - val_accuracy: 0.8158\n",
            "Epoch 210/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3563 - accuracy: 0.7445 - val_loss: 2.1917 - val_accuracy: 0.8158\n",
            "Epoch 211/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3552 - accuracy: 0.7445 - val_loss: 2.1910 - val_accuracy: 0.8158\n",
            "Epoch 212/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3542 - accuracy: 0.7445 - val_loss: 2.1905 - val_accuracy: 0.8158\n",
            "Epoch 213/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3534 - accuracy: 0.7445 - val_loss: 2.1897 - val_accuracy: 0.8158\n",
            "Epoch 214/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3524 - accuracy: 0.7445 - val_loss: 2.1892 - val_accuracy: 0.8158\n",
            "Epoch 215/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3515 - accuracy: 0.7445 - val_loss: 2.1886 - val_accuracy: 0.8158\n",
            "Epoch 216/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3506 - accuracy: 0.7489 - val_loss: 2.1880 - val_accuracy: 0.8158\n",
            "Epoch 217/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3498 - accuracy: 0.7489 - val_loss: 2.1872 - val_accuracy: 0.8158\n",
            "Epoch 218/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3488 - accuracy: 0.7489 - val_loss: 2.1866 - val_accuracy: 0.8158\n",
            "Epoch 219/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.3479 - accuracy: 0.7489 - val_loss: 2.1860 - val_accuracy: 0.8158\n",
            "Epoch 220/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3472 - accuracy: 0.7533 - val_loss: 2.1854 - val_accuracy: 0.8158\n",
            "Epoch 221/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3464 - accuracy: 0.7533 - val_loss: 2.1849 - val_accuracy: 0.8158\n",
            "Epoch 222/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3457 - accuracy: 0.7533 - val_loss: 2.1845 - val_accuracy: 0.8158\n",
            "Epoch 223/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3450 - accuracy: 0.7533 - val_loss: 2.1840 - val_accuracy: 0.8158\n",
            "Epoch 224/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3444 - accuracy: 0.7533 - val_loss: 2.1834 - val_accuracy: 0.8158\n",
            "Epoch 225/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3435 - accuracy: 0.7533 - val_loss: 2.1829 - val_accuracy: 0.8158\n",
            "Epoch 226/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3429 - accuracy: 0.7533 - val_loss: 2.1822 - val_accuracy: 0.8158\n",
            "Epoch 227/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3422 - accuracy: 0.7533 - val_loss: 2.1817 - val_accuracy: 0.8158\n",
            "Epoch 228/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3416 - accuracy: 0.7577 - val_loss: 2.1812 - val_accuracy: 0.8158\n",
            "Epoch 229/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3410 - accuracy: 0.7577 - val_loss: 2.1808 - val_accuracy: 0.8158\n",
            "Epoch 230/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3403 - accuracy: 0.7577 - val_loss: 2.1803 - val_accuracy: 0.8158\n",
            "Epoch 231/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3395 - accuracy: 0.7577 - val_loss: 2.1804 - val_accuracy: 0.7895\n",
            "Epoch 232/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3392 - accuracy: 0.7533 - val_loss: 2.1802 - val_accuracy: 0.7895\n",
            "Epoch 233/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3386 - accuracy: 0.7533 - val_loss: 2.1797 - val_accuracy: 0.7895\n",
            "Epoch 234/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3381 - accuracy: 0.7533 - val_loss: 2.1792 - val_accuracy: 0.7895\n",
            "Epoch 235/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3375 - accuracy: 0.7533 - val_loss: 2.1785 - val_accuracy: 0.7895\n",
            "Epoch 236/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3368 - accuracy: 0.7577 - val_loss: 2.1780 - val_accuracy: 0.7895\n",
            "Epoch 237/500\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 2.3363 - accuracy: 0.7621 - val_loss: 2.1780 - val_accuracy: 0.7895\n",
            "Epoch 238/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3358 - accuracy: 0.7621 - val_loss: 2.1777 - val_accuracy: 0.7895\n",
            "Epoch 239/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3352 - accuracy: 0.7621 - val_loss: 2.1773 - val_accuracy: 0.7895\n",
            "Epoch 240/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3347 - accuracy: 0.7621 - val_loss: 2.1769 - val_accuracy: 0.7895\n",
            "Epoch 241/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3342 - accuracy: 0.7665 - val_loss: 2.1764 - val_accuracy: 0.7895\n",
            "Epoch 242/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3337 - accuracy: 0.7709 - val_loss: 2.1758 - val_accuracy: 0.7895\n",
            "Epoch 243/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3332 - accuracy: 0.7709 - val_loss: 2.1754 - val_accuracy: 0.7895\n",
            "Epoch 244/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3328 - accuracy: 0.7709 - val_loss: 2.1751 - val_accuracy: 0.7895\n",
            "Epoch 245/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3321 - accuracy: 0.7709 - val_loss: 2.1754 - val_accuracy: 0.7895\n",
            "Epoch 246/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3320 - accuracy: 0.7665 - val_loss: 2.1754 - val_accuracy: 0.7895\n",
            "Epoch 247/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3313 - accuracy: 0.7577 - val_loss: 2.1750 - val_accuracy: 0.7895\n",
            "Epoch 248/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3309 - accuracy: 0.7621 - val_loss: 2.1745 - val_accuracy: 0.7895\n",
            "Epoch 249/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3304 - accuracy: 0.7621 - val_loss: 2.1739 - val_accuracy: 0.7895\n",
            "Epoch 250/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3299 - accuracy: 0.7621 - val_loss: 2.1734 - val_accuracy: 0.7895\n",
            "Epoch 251/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3294 - accuracy: 0.7621 - val_loss: 2.1730 - val_accuracy: 0.7895\n",
            "Epoch 252/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3290 - accuracy: 0.7665 - val_loss: 2.1726 - val_accuracy: 0.7895\n",
            "Epoch 253/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3286 - accuracy: 0.7709 - val_loss: 2.1723 - val_accuracy: 0.7895\n",
            "Epoch 254/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3281 - accuracy: 0.7709 - val_loss: 2.1719 - val_accuracy: 0.7895\n",
            "Epoch 255/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3278 - accuracy: 0.7709 - val_loss: 2.1715 - val_accuracy: 0.7895\n",
            "Epoch 256/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3273 - accuracy: 0.7709 - val_loss: 2.1713 - val_accuracy: 0.7895\n",
            "Epoch 257/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3270 - accuracy: 0.7709 - val_loss: 2.1708 - val_accuracy: 0.7895\n",
            "Epoch 258/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3265 - accuracy: 0.7709 - val_loss: 2.1705 - val_accuracy: 0.7895\n",
            "Epoch 259/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3261 - accuracy: 0.7709 - val_loss: 2.1703 - val_accuracy: 0.7895\n",
            "Epoch 260/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.3257 - accuracy: 0.7709 - val_loss: 2.1699 - val_accuracy: 0.7895\n",
            "Epoch 261/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3254 - accuracy: 0.7709 - val_loss: 2.1693 - val_accuracy: 0.7895\n",
            "Epoch 262/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3250 - accuracy: 0.7709 - val_loss: 2.1691 - val_accuracy: 0.7895\n",
            "Epoch 263/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3247 - accuracy: 0.7709 - val_loss: 2.1687 - val_accuracy: 0.7895\n",
            "Epoch 264/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3243 - accuracy: 0.7709 - val_loss: 2.1684 - val_accuracy: 0.7895\n",
            "Epoch 265/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 2.3240 - accuracy: 0.7709 - val_loss: 2.1682 - val_accuracy: 0.7895\n",
            "Epoch 266/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.3236 - accuracy: 0.7709 - val_loss: 2.1678 - val_accuracy: 0.7632\n",
            "Epoch 267/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.3233 - accuracy: 0.7709 - val_loss: 2.1676 - val_accuracy: 0.7632\n",
            "Epoch 268/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3229 - accuracy: 0.7709 - val_loss: 2.1672 - val_accuracy: 0.7632\n",
            "Epoch 269/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.3226 - accuracy: 0.7709 - val_loss: 2.1669 - val_accuracy: 0.7632\n",
            "Epoch 270/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3222 - accuracy: 0.7709 - val_loss: 2.1665 - val_accuracy: 0.7632\n",
            "Epoch 271/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3219 - accuracy: 0.7709 - val_loss: 2.1664 - val_accuracy: 0.7632\n",
            "Epoch 272/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 2.3216 - accuracy: 0.7709 - val_loss: 2.1659 - val_accuracy: 0.7632\n",
            "Epoch 273/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 2.3212 - accuracy: 0.7709 - val_loss: 2.1655 - val_accuracy: 0.7632\n",
            "Epoch 274/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3208 - accuracy: 0.7709 - val_loss: 2.1652 - val_accuracy: 0.7632\n",
            "Epoch 275/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 2.3205 - accuracy: 0.7709 - val_loss: 2.1653 - val_accuracy: 0.7632\n",
            "Epoch 276/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3203 - accuracy: 0.7709 - val_loss: 2.1653 - val_accuracy: 0.7632\n",
            "Epoch 277/500\n",
            "15/15 [==============================] - 0s 15ms/step - loss: 2.3200 - accuracy: 0.7709 - val_loss: 2.1649 - val_accuracy: 0.7632\n",
            "Epoch 278/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 2.3196 - accuracy: 0.7709 - val_loss: 2.1645 - val_accuracy: 0.7632\n",
            "Epoch 279/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3194 - accuracy: 0.7709 - val_loss: 2.1643 - val_accuracy: 0.7632\n",
            "Epoch 280/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3189 - accuracy: 0.7709 - val_loss: 2.1636 - val_accuracy: 0.7632\n",
            "Epoch 281/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3186 - accuracy: 0.7709 - val_loss: 2.1631 - val_accuracy: 0.7632\n",
            "Epoch 282/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3182 - accuracy: 0.7709 - val_loss: 2.1629 - val_accuracy: 0.7632\n",
            "Epoch 283/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3180 - accuracy: 0.7797 - val_loss: 2.1627 - val_accuracy: 0.7632\n",
            "Epoch 284/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3175 - accuracy: 0.7797 - val_loss: 2.1628 - val_accuracy: 0.7632\n",
            "Epoch 285/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3173 - accuracy: 0.7841 - val_loss: 2.1626 - val_accuracy: 0.7632\n",
            "Epoch 286/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.3168 - accuracy: 0.7841 - val_loss: 2.1624 - val_accuracy: 0.7632\n",
            "Epoch 287/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3166 - accuracy: 0.7841 - val_loss: 2.1619 - val_accuracy: 0.7632\n",
            "Epoch 288/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3163 - accuracy: 0.7841 - val_loss: 2.1616 - val_accuracy: 0.7632\n",
            "Epoch 289/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 2.3160 - accuracy: 0.7841 - val_loss: 2.1614 - val_accuracy: 0.7632\n",
            "Epoch 290/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3158 - accuracy: 0.7841 - val_loss: 2.1612 - val_accuracy: 0.7632\n",
            "Epoch 291/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 2.3154 - accuracy: 0.7841 - val_loss: 2.1609 - val_accuracy: 0.7632\n",
            "Epoch 292/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3152 - accuracy: 0.7841 - val_loss: 2.1607 - val_accuracy: 0.7632\n",
            "Epoch 293/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3149 - accuracy: 0.7841 - val_loss: 2.1606 - val_accuracy: 0.7632\n",
            "Epoch 294/500\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 2.3148 - accuracy: 0.7841 - val_loss: 2.1602 - val_accuracy: 0.7632\n",
            "Epoch 295/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3143 - accuracy: 0.7841 - val_loss: 2.1599 - val_accuracy: 0.7632\n",
            "Epoch 296/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3140 - accuracy: 0.7841 - val_loss: 2.1595 - val_accuracy: 0.7632\n",
            "Epoch 297/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 2.3137 - accuracy: 0.7841 - val_loss: 2.1593 - val_accuracy: 0.7632\n",
            "Epoch 298/500\n",
            "15/15 [==============================] - 0s 22ms/step - loss: 2.3136 - accuracy: 0.7841 - val_loss: 2.1592 - val_accuracy: 0.7632\n",
            "Epoch 299/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.3132 - accuracy: 0.7841 - val_loss: 2.1586 - val_accuracy: 0.7632\n",
            "Epoch 300/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3129 - accuracy: 0.7841 - val_loss: 2.1585 - val_accuracy: 0.7632\n",
            "Epoch 301/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3125 - accuracy: 0.7841 - val_loss: 2.1583 - val_accuracy: 0.7632\n",
            "Epoch 302/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3122 - accuracy: 0.7841 - val_loss: 2.1585 - val_accuracy: 0.7632\n",
            "Epoch 303/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 2.3120 - accuracy: 0.7841 - val_loss: 2.1582 - val_accuracy: 0.7632\n",
            "Epoch 304/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3117 - accuracy: 0.7885 - val_loss: 2.1581 - val_accuracy: 0.7632\n",
            "Epoch 305/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 2.3115 - accuracy: 0.7885 - val_loss: 2.1580 - val_accuracy: 0.7632\n",
            "Epoch 306/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.3112 - accuracy: 0.7885 - val_loss: 2.1578 - val_accuracy: 0.7632\n",
            "Epoch 307/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 2.3110 - accuracy: 0.7885 - val_loss: 2.1575 - val_accuracy: 0.7632\n",
            "Epoch 308/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3107 - accuracy: 0.7885 - val_loss: 2.1573 - val_accuracy: 0.7632\n",
            "Epoch 309/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3104 - accuracy: 0.7885 - val_loss: 2.1570 - val_accuracy: 0.7632\n",
            "Epoch 310/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3103 - accuracy: 0.7885 - val_loss: 2.1566 - val_accuracy: 0.7632\n",
            "Epoch 311/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3098 - accuracy: 0.7885 - val_loss: 2.1566 - val_accuracy: 0.7632\n",
            "Epoch 312/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.3095 - accuracy: 0.7885 - val_loss: 2.1565 - val_accuracy: 0.7632\n",
            "Epoch 313/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 2.3093 - accuracy: 0.7885 - val_loss: 2.1563 - val_accuracy: 0.7632\n",
            "Epoch 314/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3090 - accuracy: 0.7885 - val_loss: 2.1561 - val_accuracy: 0.7632\n",
            "Epoch 315/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.3088 - accuracy: 0.7885 - val_loss: 2.1560 - val_accuracy: 0.7632\n",
            "Epoch 316/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 2.3085 - accuracy: 0.7930 - val_loss: 2.1558 - val_accuracy: 0.7632\n",
            "Epoch 317/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.3083 - accuracy: 0.7930 - val_loss: 2.1556 - val_accuracy: 0.7632\n",
            "Epoch 318/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 2.3081 - accuracy: 0.7930 - val_loss: 2.1554 - val_accuracy: 0.7632\n",
            "Epoch 319/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.3077 - accuracy: 0.7930 - val_loss: 2.1553 - val_accuracy: 0.7632\n",
            "Epoch 320/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3076 - accuracy: 0.7930 - val_loss: 2.1553 - val_accuracy: 0.7632\n",
            "Epoch 321/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3074 - accuracy: 0.7930 - val_loss: 2.1550 - val_accuracy: 0.7632\n",
            "Epoch 322/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3071 - accuracy: 0.7930 - val_loss: 2.1549 - val_accuracy: 0.7632\n",
            "Epoch 323/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 2.3068 - accuracy: 0.7930 - val_loss: 2.1546 - val_accuracy: 0.7632\n",
            "Epoch 324/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.3066 - accuracy: 0.7974 - val_loss: 2.1545 - val_accuracy: 0.7632\n",
            "Epoch 325/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.3061 - accuracy: 0.7974 - val_loss: 2.1542 - val_accuracy: 0.7632\n",
            "Epoch 326/500\n",
            "15/15 [==============================] - 0s 20ms/step - loss: 2.3059 - accuracy: 0.7974 - val_loss: 2.1541 - val_accuracy: 0.7632\n",
            "Epoch 327/500\n",
            "15/15 [==============================] - 0s 16ms/step - loss: 2.3056 - accuracy: 0.7974 - val_loss: 2.1540 - val_accuracy: 0.7632\n",
            "Epoch 328/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 2.3053 - accuracy: 0.8018 - val_loss: 2.1536 - val_accuracy: 0.7632\n",
            "Epoch 329/500\n",
            "15/15 [==============================] - 0s 12ms/step - loss: 2.3051 - accuracy: 0.8018 - val_loss: 2.1535 - val_accuracy: 0.7632\n",
            "Epoch 330/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 2.3048 - accuracy: 0.8018 - val_loss: 2.1530 - val_accuracy: 0.7632\n",
            "Epoch 331/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 2.3044 - accuracy: 0.8018 - val_loss: 2.1528 - val_accuracy: 0.7632\n",
            "Epoch 332/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 2.3042 - accuracy: 0.8018 - val_loss: 2.1528 - val_accuracy: 0.7632\n",
            "Epoch 333/500\n",
            "15/15 [==============================] - 0s 11ms/step - loss: 2.3040 - accuracy: 0.8018 - val_loss: 2.1526 - val_accuracy: 0.7632\n",
            "Epoch 334/500\n",
            "15/15 [==============================] - 0s 9ms/step - loss: 2.3038 - accuracy: 0.8018 - val_loss: 2.1526 - val_accuracy: 0.7632\n",
            "Epoch 335/500\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 2.3035 - accuracy: 0.8018 - val_loss: 2.1530 - val_accuracy: 0.7632\n",
            "Epoch 336/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 2.3033 - accuracy: 0.8018 - val_loss: 2.1529 - val_accuracy: 0.7632\n",
            "Epoch 337/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3031 - accuracy: 0.8018 - val_loss: 2.1528 - val_accuracy: 0.7632\n",
            "Epoch 338/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.3028 - accuracy: 0.8018 - val_loss: 2.1525 - val_accuracy: 0.7632\n",
            "Epoch 339/500\n",
            "15/15 [==============================] - 0s 8ms/step - loss: 2.3025 - accuracy: 0.8018 - val_loss: 2.1521 - val_accuracy: 0.7632\n",
            "Epoch 340/500\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 2.3023 - accuracy: 0.8018 - val_loss: 2.1520 - val_accuracy: 0.7632\n",
            "Epoch 341/500\n",
            "15/15 [==============================] - 0s 14ms/step - loss: 2.3021 - accuracy: 0.8018 - val_loss: 2.1517 - val_accuracy: 0.7632\n",
            "Epoch 342/500\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 2.3018 - accuracy: 0.8018 - val_loss: 2.1517 - val_accuracy: 0.7632\n",
            "Epoch 343/500\n",
            "15/15 [==============================] - 0s 17ms/step - loss: 2.3016 - accuracy: 0.8018 - val_loss: 2.1514 - val_accuracy: 0.7632\n",
            "Epoch 344/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3013 - accuracy: 0.8018 - val_loss: 2.1513 - val_accuracy: 0.7632\n",
            "Epoch 345/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3010 - accuracy: 0.8018 - val_loss: 2.1511 - val_accuracy: 0.7632\n",
            "Epoch 346/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3008 - accuracy: 0.8018 - val_loss: 2.1510 - val_accuracy: 0.7632\n",
            "Epoch 347/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3005 - accuracy: 0.8018 - val_loss: 2.1506 - val_accuracy: 0.7632\n",
            "Epoch 348/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3004 - accuracy: 0.8018 - val_loss: 2.1503 - val_accuracy: 0.7632\n",
            "Epoch 349/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2999 - accuracy: 0.8018 - val_loss: 2.1503 - val_accuracy: 0.7632\n",
            "Epoch 350/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2998 - accuracy: 0.8018 - val_loss: 2.1498 - val_accuracy: 0.7632\n",
            "Epoch 351/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2996 - accuracy: 0.8018 - val_loss: 2.1494 - val_accuracy: 0.7632\n",
            "Epoch 352/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2991 - accuracy: 0.8018 - val_loss: 2.1490 - val_accuracy: 0.7632\n",
            "Epoch 353/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2990 - accuracy: 0.8018 - val_loss: 2.1489 - val_accuracy: 0.7632\n",
            "Epoch 354/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2988 - accuracy: 0.8018 - val_loss: 2.1487 - val_accuracy: 0.7632\n",
            "Epoch 355/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2986 - accuracy: 0.8018 - val_loss: 2.1484 - val_accuracy: 0.7632\n",
            "Epoch 356/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2983 - accuracy: 0.8018 - val_loss: 2.1485 - val_accuracy: 0.7632\n",
            "Epoch 357/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2981 - accuracy: 0.8018 - val_loss: 2.1483 - val_accuracy: 0.7632\n",
            "Epoch 358/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2978 - accuracy: 0.7974 - val_loss: 2.1481 - val_accuracy: 0.7632\n",
            "Epoch 359/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2975 - accuracy: 0.7974 - val_loss: 2.1481 - val_accuracy: 0.7632\n",
            "Epoch 360/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2972 - accuracy: 0.7974 - val_loss: 2.1479 - val_accuracy: 0.7632\n",
            "Epoch 361/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2971 - accuracy: 0.7974 - val_loss: 2.1477 - val_accuracy: 0.7632\n",
            "Epoch 362/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2968 - accuracy: 0.7974 - val_loss: 2.1476 - val_accuracy: 0.7632\n",
            "Epoch 363/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2528 - accuracy: 0.8018 - val_loss: 2.1440 - val_accuracy: 0.7895\n",
            "Epoch 364/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2399 - accuracy: 0.8018 - val_loss: 2.1427 - val_accuracy: 0.7895\n",
            "Epoch 365/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2386 - accuracy: 0.8018 - val_loss: 2.1426 - val_accuracy: 0.7895\n",
            "Epoch 366/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2367 - accuracy: 0.8018 - val_loss: 2.1427 - val_accuracy: 0.7895\n",
            "Epoch 367/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2358 - accuracy: 0.8018 - val_loss: 2.1429 - val_accuracy: 0.7895\n",
            "Epoch 368/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2352 - accuracy: 0.8018 - val_loss: 2.1426 - val_accuracy: 0.7895\n",
            "Epoch 369/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2346 - accuracy: 0.8018 - val_loss: 2.1426 - val_accuracy: 0.7895\n",
            "Epoch 370/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2340 - accuracy: 0.8018 - val_loss: 2.1426 - val_accuracy: 0.7895\n",
            "Epoch 371/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2340 - accuracy: 0.8018 - val_loss: 2.1426 - val_accuracy: 0.7895\n",
            "Epoch 372/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2335 - accuracy: 0.8018 - val_loss: 2.1426 - val_accuracy: 0.7895\n",
            "Epoch 373/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2332 - accuracy: 0.8018 - val_loss: 2.1428 - val_accuracy: 0.7895\n",
            "Epoch 374/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2327 - accuracy: 0.8018 - val_loss: 2.1426 - val_accuracy: 0.7895\n",
            "Epoch 375/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2323 - accuracy: 0.8018 - val_loss: 2.1425 - val_accuracy: 0.7895\n",
            "Epoch 376/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2321 - accuracy: 0.7974 - val_loss: 2.1423 - val_accuracy: 0.7895\n",
            "Epoch 377/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2317 - accuracy: 0.7974 - val_loss: 2.1420 - val_accuracy: 0.7895\n",
            "Epoch 378/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2314 - accuracy: 0.7974 - val_loss: 2.1416 - val_accuracy: 0.7895\n",
            "Epoch 379/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2310 - accuracy: 0.7974 - val_loss: 2.1416 - val_accuracy: 0.7895\n",
            "Epoch 380/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2306 - accuracy: 0.7974 - val_loss: 2.1413 - val_accuracy: 0.7895\n",
            "Epoch 381/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2303 - accuracy: 0.7974 - val_loss: 2.1415 - val_accuracy: 0.7895\n",
            "Epoch 382/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2300 - accuracy: 0.7974 - val_loss: 2.1416 - val_accuracy: 0.7895\n",
            "Epoch 383/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2296 - accuracy: 0.7974 - val_loss: 2.1414 - val_accuracy: 0.7895\n",
            "Epoch 384/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2294 - accuracy: 0.7974 - val_loss: 2.1412 - val_accuracy: 0.7895\n",
            "Epoch 385/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2290 - accuracy: 0.7974 - val_loss: 2.1413 - val_accuracy: 0.7895\n",
            "Epoch 386/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2288 - accuracy: 0.7974 - val_loss: 2.1412 - val_accuracy: 0.7895\n",
            "Epoch 387/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2284 - accuracy: 0.7974 - val_loss: 2.1407 - val_accuracy: 0.7895\n",
            "Epoch 388/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2280 - accuracy: 0.7974 - val_loss: 2.1408 - val_accuracy: 0.7895\n",
            "Epoch 389/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2278 - accuracy: 0.7974 - val_loss: 2.1408 - val_accuracy: 0.7895\n",
            "Epoch 390/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2274 - accuracy: 0.7974 - val_loss: 2.1407 - val_accuracy: 0.7895\n",
            "Epoch 391/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2271 - accuracy: 0.7974 - val_loss: 2.1403 - val_accuracy: 0.7895\n",
            "Epoch 392/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2269 - accuracy: 0.7974 - val_loss: 2.1405 - val_accuracy: 0.7895\n",
            "Epoch 393/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2266 - accuracy: 0.7974 - val_loss: 2.1406 - val_accuracy: 0.7895\n",
            "Epoch 394/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2262 - accuracy: 0.7974 - val_loss: 2.1406 - val_accuracy: 0.7895\n",
            "Epoch 395/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2260 - accuracy: 0.7974 - val_loss: 2.1408 - val_accuracy: 0.7895\n",
            "Epoch 396/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2257 - accuracy: 0.7930 - val_loss: 2.1407 - val_accuracy: 0.7895\n",
            "Epoch 397/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2254 - accuracy: 0.7930 - val_loss: 2.1409 - val_accuracy: 0.7895\n",
            "Epoch 398/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2252 - accuracy: 0.7930 - val_loss: 2.1409 - val_accuracy: 0.7895\n",
            "Epoch 399/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2248 - accuracy: 0.7930 - val_loss: 2.1407 - val_accuracy: 0.7895\n",
            "Epoch 400/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2247 - accuracy: 0.7930 - val_loss: 2.1409 - val_accuracy: 0.7895\n",
            "Epoch 401/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.1846 - accuracy: 0.7930 - val_loss: 2.1409 - val_accuracy: 0.8158\n",
            "Epoch 402/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2696 - accuracy: 0.7974 - val_loss: 2.1461 - val_accuracy: 0.8158\n",
            "Epoch 403/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2626 - accuracy: 0.7974 - val_loss: 2.1476 - val_accuracy: 0.8158\n",
            "Epoch 404/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2611 - accuracy: 0.8062 - val_loss: 2.1480 - val_accuracy: 0.8158\n",
            "Epoch 405/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2604 - accuracy: 0.8062 - val_loss: 2.1473 - val_accuracy: 0.8421\n",
            "Epoch 406/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2594 - accuracy: 0.8062 - val_loss: 2.1470 - val_accuracy: 0.8421\n",
            "Epoch 407/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2588 - accuracy: 0.8062 - val_loss: 2.1466 - val_accuracy: 0.8421\n",
            "Epoch 408/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2583 - accuracy: 0.8062 - val_loss: 2.1463 - val_accuracy: 0.8421\n",
            "Epoch 409/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2576 - accuracy: 0.8062 - val_loss: 2.1459 - val_accuracy: 0.8421\n",
            "Epoch 410/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2572 - accuracy: 0.8018 - val_loss: 2.1454 - val_accuracy: 0.8421\n",
            "Epoch 411/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2566 - accuracy: 0.8018 - val_loss: 2.1449 - val_accuracy: 0.8421\n",
            "Epoch 412/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2561 - accuracy: 0.8018 - val_loss: 2.1448 - val_accuracy: 0.8421\n",
            "Epoch 413/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2557 - accuracy: 0.8018 - val_loss: 2.1447 - val_accuracy: 0.8421\n",
            "Epoch 414/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2553 - accuracy: 0.8150 - val_loss: 2.1441 - val_accuracy: 0.8421\n",
            "Epoch 415/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2548 - accuracy: 0.8150 - val_loss: 2.1437 - val_accuracy: 0.8421\n",
            "Epoch 416/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2544 - accuracy: 0.8150 - val_loss: 2.1434 - val_accuracy: 0.8421\n",
            "Epoch 417/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2540 - accuracy: 0.8150 - val_loss: 2.1432 - val_accuracy: 0.8421\n",
            "Epoch 418/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2536 - accuracy: 0.8150 - val_loss: 2.1429 - val_accuracy: 0.8421\n",
            "Epoch 419/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2531 - accuracy: 0.8150 - val_loss: 2.1423 - val_accuracy: 0.8421\n",
            "Epoch 420/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2528 - accuracy: 0.8150 - val_loss: 2.1422 - val_accuracy: 0.8421\n",
            "Epoch 421/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2525 - accuracy: 0.8150 - val_loss: 2.1420 - val_accuracy: 0.8421\n",
            "Epoch 422/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2521 - accuracy: 0.8150 - val_loss: 2.1420 - val_accuracy: 0.8421\n",
            "Epoch 423/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2519 - accuracy: 0.8150 - val_loss: 2.1420 - val_accuracy: 0.8421\n",
            "Epoch 424/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2516 - accuracy: 0.8150 - val_loss: 2.1420 - val_accuracy: 0.8421\n",
            "Epoch 425/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2513 - accuracy: 0.8150 - val_loss: 2.1416 - val_accuracy: 0.8421\n",
            "Epoch 426/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2510 - accuracy: 0.8106 - val_loss: 2.1417 - val_accuracy: 0.8421\n",
            "Epoch 427/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2507 - accuracy: 0.8106 - val_loss: 2.1416 - val_accuracy: 0.8421\n",
            "Epoch 428/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2505 - accuracy: 0.8106 - val_loss: 2.1414 - val_accuracy: 0.8421\n",
            "Epoch 429/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2502 - accuracy: 0.8106 - val_loss: 2.1413 - val_accuracy: 0.8421\n",
            "Epoch 430/500\n",
            "15/15 [==============================] - 0s 7ms/step - loss: 2.2500 - accuracy: 0.8106 - val_loss: 2.1413 - val_accuracy: 0.8421\n",
            "Epoch 431/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2498 - accuracy: 0.8106 - val_loss: 2.1412 - val_accuracy: 0.8421\n",
            "Epoch 432/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2495 - accuracy: 0.8150 - val_loss: 2.1409 - val_accuracy: 0.8421\n",
            "Epoch 433/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2492 - accuracy: 0.8150 - val_loss: 2.1408 - val_accuracy: 0.8421\n",
            "Epoch 434/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2490 - accuracy: 0.8150 - val_loss: 2.1406 - val_accuracy: 0.8421\n",
            "Epoch 435/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2487 - accuracy: 0.8150 - val_loss: 2.1414 - val_accuracy: 0.8421\n",
            "Epoch 436/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2485 - accuracy: 0.8150 - val_loss: 2.1415 - val_accuracy: 0.8421\n",
            "Epoch 437/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2483 - accuracy: 0.8150 - val_loss: 2.1413 - val_accuracy: 0.8421\n",
            "Epoch 438/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2481 - accuracy: 0.8150 - val_loss: 2.1411 - val_accuracy: 0.8421\n",
            "Epoch 439/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2478 - accuracy: 0.8150 - val_loss: 2.1410 - val_accuracy: 0.8421\n",
            "Epoch 440/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2475 - accuracy: 0.8150 - val_loss: 2.1406 - val_accuracy: 0.8421\n",
            "Epoch 441/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2473 - accuracy: 0.8150 - val_loss: 2.1401 - val_accuracy: 0.8421\n",
            "Epoch 442/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2471 - accuracy: 0.8150 - val_loss: 2.1399 - val_accuracy: 0.8421\n",
            "Epoch 443/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2469 - accuracy: 0.8150 - val_loss: 2.1400 - val_accuracy: 0.8421\n",
            "Epoch 444/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2468 - accuracy: 0.8150 - val_loss: 2.1398 - val_accuracy: 0.8421\n",
            "Epoch 445/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2466 - accuracy: 0.8150 - val_loss: 2.1395 - val_accuracy: 0.8421\n",
            "Epoch 446/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 2.2464 - accuracy: 0.8150 - val_loss: 2.1395 - val_accuracy: 0.8421\n",
            "Epoch 447/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2462 - accuracy: 0.8150 - val_loss: 2.1397 - val_accuracy: 0.8421\n",
            "Epoch 448/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2047 - accuracy: 0.8150 - val_loss: 2.1395 - val_accuracy: 0.8421\n",
            "Epoch 449/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.9782 - accuracy: 0.8238 - val_loss: 2.1392 - val_accuracy: 0.8158\n",
            "Epoch 450/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.9474 - accuracy: 0.8194 - val_loss: 2.1396 - val_accuracy: 0.8158\n",
            "Epoch 451/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8918 - accuracy: 0.8194 - val_loss: 2.1401 - val_accuracy: 0.8158\n",
            "Epoch 452/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8854 - accuracy: 0.8194 - val_loss: 2.1395 - val_accuracy: 0.8158\n",
            "Epoch 453/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8820 - accuracy: 0.8150 - val_loss: 2.1395 - val_accuracy: 0.8158\n",
            "Epoch 454/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8793 - accuracy: 0.8150 - val_loss: 2.1395 - val_accuracy: 0.8158\n",
            "Epoch 455/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8782 - accuracy: 0.8150 - val_loss: 2.1403 - val_accuracy: 0.8158\n",
            "Epoch 456/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8762 - accuracy: 0.8238 - val_loss: 2.1408 - val_accuracy: 0.8158\n",
            "Epoch 457/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8748 - accuracy: 0.8238 - val_loss: 2.1420 - val_accuracy: 0.7895\n",
            "Epoch 458/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8739 - accuracy: 0.8194 - val_loss: 2.1423 - val_accuracy: 0.8158\n",
            "Epoch 459/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8732 - accuracy: 0.8150 - val_loss: 2.1426 - val_accuracy: 0.7632\n",
            "Epoch 460/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8724 - accuracy: 0.8150 - val_loss: 2.1426 - val_accuracy: 0.7895\n",
            "Epoch 461/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8718 - accuracy: 0.8150 - val_loss: 2.1427 - val_accuracy: 0.7895\n",
            "Epoch 462/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8712 - accuracy: 0.8238 - val_loss: 2.1428 - val_accuracy: 0.7895\n",
            "Epoch 463/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8705 - accuracy: 0.8238 - val_loss: 2.1428 - val_accuracy: 0.7895\n",
            "Epoch 464/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8700 - accuracy: 0.8238 - val_loss: 2.1430 - val_accuracy: 0.7895\n",
            "Epoch 465/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8696 - accuracy: 0.8238 - val_loss: 2.1431 - val_accuracy: 0.7895\n",
            "Epoch 466/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8686 - accuracy: 0.8238 - val_loss: 2.1432 - val_accuracy: 0.7895\n",
            "Epoch 467/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8682 - accuracy: 0.8238 - val_loss: 2.1434 - val_accuracy: 0.7895\n",
            "Epoch 468/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8677 - accuracy: 0.8238 - val_loss: 2.1436 - val_accuracy: 0.7895\n",
            "Epoch 469/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8676 - accuracy: 0.8238 - val_loss: 2.1437 - val_accuracy: 0.7895\n",
            "Epoch 470/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8669 - accuracy: 0.8238 - val_loss: 2.1439 - val_accuracy: 0.7895\n",
            "Epoch 471/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8666 - accuracy: 0.8194 - val_loss: 2.1447 - val_accuracy: 0.7895\n",
            "Epoch 472/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8287 - accuracy: 0.8150 - val_loss: 2.1560 - val_accuracy: 0.7895\n",
            "Epoch 473/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8107 - accuracy: 0.8150 - val_loss: 2.1674 - val_accuracy: 0.7895\n",
            "Epoch 474/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.8096 - accuracy: 0.8194 - val_loss: 2.1691 - val_accuracy: 0.7895\n",
            "Epoch 475/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8086 - accuracy: 0.8194 - val_loss: 2.1690 - val_accuracy: 0.7895\n",
            "Epoch 476/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8078 - accuracy: 0.8194 - val_loss: 2.1684 - val_accuracy: 0.7895\n",
            "Epoch 477/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8070 - accuracy: 0.8282 - val_loss: 2.1684 - val_accuracy: 0.7895\n",
            "Epoch 478/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8064 - accuracy: 0.8282 - val_loss: 2.1678 - val_accuracy: 0.7895\n",
            "Epoch 479/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8055 - accuracy: 0.8282 - val_loss: 2.1672 - val_accuracy: 0.7895\n",
            "Epoch 480/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8048 - accuracy: 0.8282 - val_loss: 2.1669 - val_accuracy: 0.7895\n",
            "Epoch 481/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8041 - accuracy: 0.8282 - val_loss: 2.1663 - val_accuracy: 0.7895\n",
            "Epoch 482/500\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 1.7646 - accuracy: 0.8194 - val_loss: 2.1665 - val_accuracy: 0.7895\n",
            "Epoch 483/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.6900 - accuracy: 0.8282 - val_loss: 2.1688 - val_accuracy: 0.7895\n",
            "Epoch 484/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.6869 - accuracy: 0.8282 - val_loss: 2.1692 - val_accuracy: 0.7895\n",
            "Epoch 485/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.6441 - accuracy: 0.8282 - val_loss: 2.1750 - val_accuracy: 0.7632\n",
            "Epoch 486/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.5704 - accuracy: 0.8238 - val_loss: 2.1804 - val_accuracy: 0.7632\n",
            "Epoch 487/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5662 - accuracy: 0.8238 - val_loss: 2.1816 - val_accuracy: 0.7632\n",
            "Epoch 488/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5654 - accuracy: 0.8238 - val_loss: 2.1817 - val_accuracy: 0.7632\n",
            "Epoch 489/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5648 - accuracy: 0.8238 - val_loss: 2.1820 - val_accuracy: 0.7632\n",
            "Epoch 490/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.5642 - accuracy: 0.8238 - val_loss: 2.1818 - val_accuracy: 0.7632\n",
            "Epoch 491/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5638 - accuracy: 0.8238 - val_loss: 2.1816 - val_accuracy: 0.7632\n",
            "Epoch 492/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.5633 - accuracy: 0.8238 - val_loss: 2.1815 - val_accuracy: 0.7632\n",
            "Epoch 493/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5628 - accuracy: 0.8238 - val_loss: 2.1812 - val_accuracy: 0.7632\n",
            "Epoch 494/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5623 - accuracy: 0.8282 - val_loss: 2.1810 - val_accuracy: 0.7632\n",
            "Epoch 495/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.5618 - accuracy: 0.8282 - val_loss: 2.1807 - val_accuracy: 0.7632\n",
            "Epoch 496/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.5614 - accuracy: 0.8282 - val_loss: 2.1802 - val_accuracy: 0.7632\n",
            "Epoch 497/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5606 - accuracy: 0.8282 - val_loss: 2.1791 - val_accuracy: 0.7632\n",
            "Epoch 498/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.5604 - accuracy: 0.8282 - val_loss: 2.1793 - val_accuracy: 0.7632\n",
            "Epoch 499/500\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5596 - accuracy: 0.8282 - val_loss: 2.1791 - val_accuracy: 0.7632\n",
            "Epoch 500/500\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.5592 - accuracy: 0.8282 - val_loss: 2.1791 - val_accuracy: 0.7632\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(train_X, train_y, verbose=1, validation_data=(val_X, val_y), batch_size=16, epochs=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mx4N7uO-9Uy"
      },
      "source": [
        "Evaluate your testing split, to get the accuracy and the loss score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9Jzj9resfZF",
        "outputId": "d8d9833a-e43c-4e5a-ae7b-da6999a33ccf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test fraction correct (NN-Loss) = 0.95\n",
            "Test fraction correct (NN-Accuracy) = 0.87\n"
          ]
        }
      ],
      "source": [
        "score, accuracy = model.evaluate(test_X, test_y, batch_size=16, verbose=0)\n",
        "print(\"Test fraction correct (NN-Loss) = {:.2f}\".format(score))\n",
        "print(\"Test fraction correct (NN-Accuracy) = {:.2f}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YaAr-aeAHBW"
      },
      "source": [
        "### 1.2.2.6 Visualize Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-h-R6YS_Ptd"
      },
      "source": [
        "Plot the training and validation accuracy. Try to interpret those plots. \n",
        "\n",
        "\n",
        "**TODO: for each experiment you make, include this plot and indicate whether there exist any type of *overfitting or underfitting*.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "G0eaLehNp0ES",
        "outputId": "3a4bdedc-cd89-40cd-e6db-e32357f30780",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Get training and test loss histories\n",
        "training_loss = hist.history['accuracy']\n",
        "val_loss = hist.history['val_accuracy']\n",
        "\n",
        "# Create count of the number of epochs\n",
        "epoch_count = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Visualize loss history\n",
        "plt.figure()\n",
        "plt.plot(epoch_count, training_loss, 'r--')\n",
        "plt.plot(epoch_count, val_loss, 'b-')\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0vr8s80Aljv"
      },
      "source": [
        "## 1.2.3 Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK6q-eIkAqmG"
      },
      "source": [
        "That's it! Congratulations on training a logistic regression model.\n",
        "\n",
        "Make sure you deliver all the requirements for the submission."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "tcTmEu8AAA4W"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
